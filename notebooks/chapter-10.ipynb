{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "occupied-moore",
   "metadata": {},
   "source": [
    "# Chapter 10: Iris, Fashion MNIST & District Housing\n",
    "\n",
    "This notebook contains the code for chapter 10 of the Hands-on Machine Learning with Scikit-Learn, Keras & Tensorflow book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lucky-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing, load_iris\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from scipy.stats import reciprocal\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.models import Model, Sequential, clone_model, load_model\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Flatten, Input\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-dancing",
   "metadata": {},
   "source": [
    "## Global configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ethical-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_PATH = \"../logs/\"\n",
    "\n",
    "MODEL_PATH = \"../models/\"\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "JOB_COUNT = 1 # FIX: gpu out of memory error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lesser-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0072c74",
   "metadata": {},
   "source": [
    "## Load <ins>iris</ins> data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "597908be",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb25ad3",
   "metadata": {},
   "source": [
    "## Split <ins>iris</ins> data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "136f6645",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = iris.data[:, (2, 3)], (iris.target == 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2945a7",
   "metadata": {},
   "source": [
    "## Train <ins>perceptron</ins> model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "878723ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_model = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f48606d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 404 µs, sys: 547 µs, total: 951 µs\n",
      "Wall time: 804 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "per_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3da395",
   "metadata": {},
   "source": [
    "## Evaluate <ins>perceptron</ins> model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7d891fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_model.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0b511a",
   "metadata": {},
   "source": [
    "## Load <ins>fashion MNIST</ins> data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "407579f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7dbfce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class_names = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285bcf3e",
   "metadata": {},
   "source": [
    "## Split <ins>fashion MNIST</ins> data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1de514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_validation, y_validation = X_train[5000:], y_train[5000:], X_train[:5000], y_train[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59f2069",
   "metadata": {},
   "source": [
    "## Scale <ins>fashion MNIST</ins> data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d06e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation = X_train / 255.0, X_validation / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5c5f05",
   "metadata": {},
   "source": [
    "## Create <ins>sequential</ins> model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7e6a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc57fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model = Sequential()\n",
    "\n",
    "seq_model.add(Flatten(input_shape=[28, 28]))\n",
    "seq_model.add(Dense(300, activation=\"relu\"))\n",
    "seq_model.add(Dense(100, activation=\"relu\"))\n",
    "seq_model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d48c7a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb1b8f3",
   "metadata": {},
   "source": [
    "## Inspect <ins>sequential</ins> model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61564d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7fa660242970>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense = seq_model.get_layer(seq_model.layers[1].name)\n",
    "dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee02c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = dense.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09a45b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.02448617, -0.00877795, -0.02189048, ..., -0.02766046,\n",
       "          0.03859074, -0.06889391],\n",
       "        [ 0.00476504, -0.03105379, -0.0586676 , ...,  0.00602964,\n",
       "         -0.02763776, -0.04165364],\n",
       "        [-0.06189284, -0.06901957,  0.07102345, ..., -0.04238207,\n",
       "          0.07121518, -0.07331658],\n",
       "        ...,\n",
       "        [-0.03048757,  0.02155137, -0.05400612, ..., -0.00113463,\n",
       "          0.00228987,  0.05581069],\n",
       "        [ 0.07061854, -0.06960931,  0.07038955, ..., -0.00384101,\n",
       "          0.00034875,  0.02878492],\n",
       "        [-0.06022581,  0.01577859, -0.02585464, ..., -0.00527829,\n",
       "          0.00272203, -0.06793761]], dtype=float32),\n",
       " (784, 300))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92d57821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " (300,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases, biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3df702",
   "metadata": {},
   "source": [
    "## Compile <ins>sequential</ins> model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fac0fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a2d772",
   "metadata": {},
   "source": [
    "## Train <ins>sequential</ins> model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48b9bc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.0187 - accuracy: 0.6805 - val_loss: 0.5213 - val_accuracy: 0.8226\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5027 - accuracy: 0.8262 - val_loss: 0.4353 - val_accuracy: 0.8526\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4483 - accuracy: 0.8426 - val_loss: 0.5338 - val_accuracy: 0.7992\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4208 - accuracy: 0.8530 - val_loss: 0.3911 - val_accuracy: 0.8650\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4061 - accuracy: 0.8580 - val_loss: 0.3743 - val_accuracy: 0.8698\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3754 - accuracy: 0.8673 - val_loss: 0.3712 - val_accuracy: 0.8726\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3654 - accuracy: 0.8710 - val_loss: 0.3614 - val_accuracy: 0.8728\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3481 - accuracy: 0.8752 - val_loss: 0.3849 - val_accuracy: 0.8622\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3484 - accuracy: 0.8763 - val_loss: 0.3581 - val_accuracy: 0.8712\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3296 - accuracy: 0.8836 - val_loss: 0.3425 - val_accuracy: 0.8782\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3216 - accuracy: 0.8840 - val_loss: 0.3438 - val_accuracy: 0.8790\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3120 - accuracy: 0.8875 - val_loss: 0.3305 - val_accuracy: 0.8824\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3051 - accuracy: 0.8900 - val_loss: 0.3267 - val_accuracy: 0.8870\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2990 - accuracy: 0.8918 - val_loss: 0.3405 - val_accuracy: 0.8776\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2930 - accuracy: 0.8947 - val_loss: 0.3219 - val_accuracy: 0.8846\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2859 - accuracy: 0.8981 - val_loss: 0.3094 - val_accuracy: 0.8904\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2778 - accuracy: 0.9010 - val_loss: 0.3559 - val_accuracy: 0.8730\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2775 - accuracy: 0.8998 - val_loss: 0.3127 - val_accuracy: 0.8880\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2740 - accuracy: 0.9023 - val_loss: 0.3116 - val_accuracy: 0.8912\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2696 - accuracy: 0.9043 - val_loss: 0.3281 - val_accuracy: 0.8810\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2670 - accuracy: 0.9047 - val_loss: 0.3052 - val_accuracy: 0.8918\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2612 - accuracy: 0.9052 - val_loss: 0.2963 - val_accuracy: 0.8968\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2549 - accuracy: 0.9081 - val_loss: 0.3004 - val_accuracy: 0.8922\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2452 - accuracy: 0.9120 - val_loss: 0.3076 - val_accuracy: 0.8884\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2492 - accuracy: 0.9110 - val_loss: 0.2990 - val_accuracy: 0.8942\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2425 - accuracy: 0.9133 - val_loss: 0.3073 - val_accuracy: 0.8912\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2372 - accuracy: 0.9160 - val_loss: 0.3005 - val_accuracy: 0.8954\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2314 - accuracy: 0.9174 - val_loss: 0.3002 - val_accuracy: 0.8928\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2279 - accuracy: 0.9181 - val_loss: 0.3046 - val_accuracy: 0.8924\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2248 - accuracy: 0.9212 - val_loss: 0.3027 - val_accuracy: 0.8934\n",
      "CPU times: user 2min 7s, sys: 12 s, total: 2min 19s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seq_model_history = seq_model.fit(X_train, y_train, epochs=30, validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2ab4b5",
   "metadata": {},
   "source": [
    "## Plot <ins>sequential</ins> model (learning cuves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cff02f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seq_model_history = pd.DataFrame(seq_model_history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94fca85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_seq_model_history.plot(\n",
    "    ylim=(0, 1),\n",
    "    grid=True,\n",
    "    figsize=(12, 6),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a1a9c",
   "metadata": {},
   "source": [
    "## Evaluate <ins>sequential</ins> model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0b51862",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new, y_test_new = X_test[:3], y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93c80d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_new_probabilities = seq_model.predict(X_test_new)\n",
    "y_test_new_probabilities.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3824cb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9, 2, 1]), array([9, 2, 1], dtype=uint8))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_new_predictions = np.argmax(seq_model.predict(X_test_new), axis=-1)\n",
    "\n",
    "y_test_new_predictions, y_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08f00705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11'),\n",
       " array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_class_names)[y_test_new_predictions], np.array(y_class_names)[y_test_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74e03a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 78.8121 - accuracy: 0.8298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[78.81205749511719, 0.829800009727478]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c2fbe4",
   "metadata": {},
   "source": [
    "## Load <ins>housing</ins> data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bfc93cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a54418",
   "metadata": {},
   "source": [
    "## Split <ins>housing</ins> data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0938003",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(housing.data, housing.target, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4733e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2356f41b",
   "metadata": {},
   "source": [
    "## Scale <ins>housing</ins> data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7b125ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d61cc87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.28 ms, sys: 258 µs, total: 2.54 ms\n",
      "Wall time: 1.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = standard_scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eda6b4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 472 µs, sys: 0 ns, total: 472 µs\n",
      "Wall time: 309 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_validation = standard_scaler.transform(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2f2635b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 783 µs, sys: 0 ns, total: 783 µs\n",
      "Wall time: 472 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test = standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564f33fc",
   "metadata": {},
   "source": [
    "## Create <ins>sequential</ins> model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d232ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7eee54c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model = Sequential([\n",
    "    Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d35cdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d97977",
   "metadata": {},
   "source": [
    "## Compile <ins>sequential</ins> model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c4f592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7313ac",
   "metadata": {},
   "source": [
    "## Train <ins>sequential</ins> model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b64e226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1624 - val_loss: 12.0173\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9593 - val_loss: 2.2028\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4705 - val_loss: 0.3950\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4259 - val_loss: 0.4055\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4124 - val_loss: 0.4103\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3945 - val_loss: 0.4421\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4139 - val_loss: 0.4121\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.4069\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.4060\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.4093\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.3848\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.4045\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3699 - val_loss: 0.3945\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3642 - val_loss: 0.3623\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3667 - val_loss: 0.3737\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3705 - val_loss: 0.3656\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.3926\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3588 - val_loss: 0.3698\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3504 - val_loss: 0.3544\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3404 - val_loss: 0.3813\n",
      "CPU times: user 18.9 s, sys: 1.78 s, total: 20.7 s\n",
      "Wall time: 9.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seq_model_history = seq_model.fit(X_train, y_train, epochs=20, validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b7ab93",
   "metadata": {},
   "source": [
    "## Evaluate <ins>sequential</ins> model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "601e19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new, y_test_new = X_test[:3], y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8978620f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.59521866],\n",
       "        [1.7537185 ],\n",
       "        [4.221365  ]], dtype=float32),\n",
       " array([0.477  , 0.458  , 5.00001]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_new_predictions = seq_model.predict(X_test_new)\n",
    "\n",
    "y_test_new_predictions, y_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7168bd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 738us/step - loss: 0.3500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.350009560585022"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4448472",
   "metadata": {},
   "source": [
    "## Transform <ins>housing</ins> data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "baab2048",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a, X_train_b = X_train[:, :5], X_train[:, 2:]\n",
    "X_validation_a, X_validation_b = X_validation[:, :5], X_validation[:, 2:]\n",
    "X_test_a, X_test_b = X_test[:, :5], X_test[:, 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47315bbe",
   "metadata": {},
   "source": [
    "## Create <ins>non-sequential</ins> model (single-input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83873ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "548019ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=X_train.shape[1:])\n",
    "\n",
    "hidden_layer_1 = Dense(30, activation=\"relu\")(input_layer)\n",
    "hidden_layer_2 = Dense(30, activation=\"relu\")(hidden_layer_1)\n",
    "\n",
    "concat_layer = Concatenate()([input_layer, hidden_layer_2])\n",
    "\n",
    "output_layer = Dense(1)(concat_layer)\n",
    "\n",
    "non_seq_si_model = Model(inputs=[input_layer], outputs=[output_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f94a16ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30)           270         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30)           930         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            39          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "non_seq_si_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1545de5e",
   "metadata": {},
   "source": [
    "## Create <ins>non-sequential</ins> model (multi-input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "36a018fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "488f7848",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_a = Input(shape=[5])\n",
    "input_layer_b = Input(shape=[6])\n",
    "\n",
    "hidden_layer_1 = Dense(30, activation=\"relu\")(input_layer_b)\n",
    "hidden_layer_2 = Dense(30, activation=\"relu\")(hidden_layer_1)\n",
    "\n",
    "concat_layer = Concatenate()([input_layer_a, hidden_layer_2])\n",
    "\n",
    "output_layer = Dense(1)(concat_layer)\n",
    "\n",
    "non_seq_mi_model = Model(inputs=[input_layer_a, input_layer_b], outputs=[output_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29461355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30)           210         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30)           930         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 35)           0           input_1[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            36          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,176\n",
      "Trainable params: 1,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "non_seq_mi_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74ef82c",
   "metadata": {},
   "source": [
    "## Compile <ins>non-sequential</ins> model (multi-input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fe2e6bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_seq_mi_model.compile(loss=\"mse\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64b6da3",
   "metadata": {},
   "source": [
    "## Train <ins>non-sequential</ins> model (multi-input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0eff90fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1943 - val_loss: 2.9992\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6168 - val_loss: 9.4370\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5845 - val_loss: 0.4052\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4480 - val_loss: 0.4030\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4260 - val_loss: 0.3873\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4152 - val_loss: 0.4463\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4321 - val_loss: 0.3791\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4097 - val_loss: 0.3706\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3933 - val_loss: 0.4185\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3891 - val_loss: 0.3554\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3899 - val_loss: 0.3682\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3945 - val_loss: 0.3990\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.3464\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3724 - val_loss: 0.3621\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3756 - val_loss: 0.4224\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3759 - val_loss: 0.5013\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3751 - val_loss: 0.5222\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3667 - val_loss: 0.4289\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3533 - val_loss: 0.3336\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3455 - val_loss: 0.3461\n",
      "CPU times: user 22.5 s, sys: 2.03 s, total: 24.5 s\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "non_seq_mi_model_history = non_seq_mi_model.fit(\n",
    "    (X_train_a, X_train_b),\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    validation_data=((X_validation_a, X_validation_b), y_validation),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d4dbcf",
   "metadata": {},
   "source": [
    "## Evaluate <ins>non-sequential</ins> model (multi-input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af6a6424",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new_a, X_test_new_b, y_test_new = X_test_a[:3], X_test_b[:3], y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "807b91da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.5409373],\n",
       "        [1.5530725],\n",
       "        [3.609915 ]], dtype=float32),\n",
       " array([0.477  , 0.458  , 5.00001]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_new_predictions = non_seq_mi_model.predict((X_test_new_a, X_test_new_b))\n",
    "\n",
    "y_test_new_predictions, y_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3542c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 800us/step - loss: 0.3480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3480260670185089"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_seq_mi_model.evaluate((X_test_a, X_test_b), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91a6a4e",
   "metadata": {},
   "source": [
    "## Create <ins>non-sequential</ins> model (multi-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9418c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab9066d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_a = Input(shape=[5])\n",
    "input_layer_b = Input(shape=[6])\n",
    "\n",
    "hidden_layer_1 = Dense(30, activation=\"relu\")(input_layer_b)\n",
    "hidden_layer_2 = Dense(30, activation=\"relu\")(hidden_layer_1)\n",
    "\n",
    "concat_layer = Concatenate()([input_layer_a, hidden_layer_2])\n",
    "\n",
    "output_layer_1 = Dense(1)(concat_layer)\n",
    "output_layer_2 = Dense(1)(hidden_layer_2)\n",
    "\n",
    "non_seq_mo_model = Model(inputs=[input_layer_a, input_layer_b], outputs=[output_layer_1, output_layer_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a73a0df2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30)           210         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30)           930         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 35)           0           input_1[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            36          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            31          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,207\n",
      "Trainable params: 1,207\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "non_seq_mo_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae19ca01",
   "metadata": {},
   "source": [
    "## Compile <ins>non-sequential</ins> model (multi-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "87e458f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_seq_mo_model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2244ca80",
   "metadata": {},
   "source": [
    "## Train <ins>non-sequential</ins> model (multi-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "428965f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.6362 - dense_2_loss: 1.4809 - dense_3_loss: 3.0330 - val_loss: 1.2866 - val_dense_2_loss: 1.1465 - val_dense_3_loss: 2.5472\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5743 - dense_2_loss: 0.5112 - dense_3_loss: 1.1417 - val_loss: 0.5120 - val_dense_2_loss: 0.4626 - val_dense_3_loss: 0.9564\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4865 - dense_2_loss: 0.4469 - dense_3_loss: 0.8429 - val_loss: 0.4329 - val_dense_2_loss: 0.4008 - val_dense_3_loss: 0.7217\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4639 - dense_2_loss: 0.4356 - dense_3_loss: 0.7187 - val_loss: 0.4384 - val_dense_2_loss: 0.4154 - val_dense_3_loss: 0.6453\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4426 - dense_2_loss: 0.4181 - dense_3_loss: 0.6631 - val_loss: 0.4188 - val_dense_2_loss: 0.3993 - val_dense_3_loss: 0.5947\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4285 - dense_2_loss: 0.4091 - dense_3_loss: 0.6028 - val_loss: 0.5450 - val_dense_2_loss: 0.5314 - val_dense_3_loss: 0.6668\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4545 - dense_2_loss: 0.4317 - dense_3_loss: 0.6598 - val_loss: 0.4172 - val_dense_2_loss: 0.4017 - val_dense_3_loss: 0.5574\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4237 - dense_2_loss: 0.4045 - dense_3_loss: 0.5964 - val_loss: 0.3989 - val_dense_2_loss: 0.3820 - val_dense_3_loss: 0.5509\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4054 - dense_2_loss: 0.3876 - dense_3_loss: 0.5656 - val_loss: 0.3993 - val_dense_2_loss: 0.3831 - val_dense_3_loss: 0.5454\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4003 - dense_2_loss: 0.3816 - dense_3_loss: 0.5694 - val_loss: 0.3999 - val_dense_2_loss: 0.3851 - val_dense_3_loss: 0.5332\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3901 - dense_2_loss: 0.3734 - dense_3_loss: 0.5408 - val_loss: 0.3756 - val_dense_2_loss: 0.3580 - val_dense_3_loss: 0.5343\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3914 - dense_2_loss: 0.3740 - dense_3_loss: 0.5476 - val_loss: 0.3829 - val_dense_2_loss: 0.3677 - val_dense_3_loss: 0.5205\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3854 - dense_2_loss: 0.3706 - dense_3_loss: 0.5184 - val_loss: 0.3787 - val_dense_2_loss: 0.3633 - val_dense_3_loss: 0.5174\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3809 - dense_2_loss: 0.3635 - dense_3_loss: 0.5374 - val_loss: 0.3548 - val_dense_2_loss: 0.3347 - val_dense_3_loss: 0.5356\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3766 - dense_2_loss: 0.3619 - dense_3_loss: 0.5094 - val_loss: 0.3614 - val_dense_2_loss: 0.3429 - val_dense_3_loss: 0.5284\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3810 - dense_2_loss: 0.3661 - dense_3_loss: 0.5159 - val_loss: 0.3547 - val_dense_2_loss: 0.3363 - val_dense_3_loss: 0.5199\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3755 - dense_2_loss: 0.3614 - dense_3_loss: 0.5021 - val_loss: 0.3780 - val_dense_2_loss: 0.3608 - val_dense_3_loss: 0.5324\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3722 - dense_2_loss: 0.3563 - dense_3_loss: 0.5153 - val_loss: 0.3569 - val_dense_2_loss: 0.3399 - val_dense_3_loss: 0.5105\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3596 - dense_2_loss: 0.3451 - dense_3_loss: 0.4895 - val_loss: 0.3491 - val_dense_2_loss: 0.3319 - val_dense_3_loss: 0.5031\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3554 - dense_2_loss: 0.3411 - dense_3_loss: 0.4836 - val_loss: 0.3449 - val_dense_2_loss: 0.3285 - val_dense_3_loss: 0.4918\n",
      "CPU times: user 29.1 s, sys: 3.28 s, total: 32.4 s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "non_seq_mo_model_history = non_seq_mo_model.fit(\n",
    "    (X_train_a, X_train_b),\n",
    "    (y_train, y_train),\n",
    "    epochs=20,\n",
    "    validation_data=((X_validation_a, X_validation_b), (y_validation, y_validation)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d680122",
   "metadata": {},
   "source": [
    "## Evaluate <ins>non-sequential</ins> model (multi-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "26427d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.50409424],\n",
       "        [1.5349944 ],\n",
       "        [3.5876977 ]], dtype=float32),\n",
       " array([[0.7805631],\n",
       "        [1.8662858],\n",
       "        [3.0616472]], dtype=float32),\n",
       " array([0.477  , 0.458  , 5.00001]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_new_predictions_1, y_test_new_predictions_2 = non_seq_mo_model.predict((X_test_new_a, X_test_new_b))\n",
    "\n",
    "y_test_new_predictions_1, y_test_new_predictions_2, y_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1171a9b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3588 - dense_2_loss: 0.3451 - dense_3_loss: 0.4814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35875412821769714, 0.345126211643219, 0.4814044237136841]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_seq_mo_model.evaluate((X_test_a, X_test_b), (y_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a286f7",
   "metadata": {},
   "source": [
    "## Save <ins>non-sequential</ins> model (multi-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "022db58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_seq_mo_model.save(MODEL_PATH + \"district-housing-pricing-nsqmom-v0.1.0.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fa7294",
   "metadata": {},
   "source": [
    "## Load <ins>non-sequential</ins> model (multi-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "667a06a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_seq_mo_model = load_model(MODEL_PATH + \"district-housing-pricing-nsqmom-v0.1.0.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a66479",
   "metadata": {},
   "source": [
    "## Clone <ins>non-sequential</ins> model (single-input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c26adb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "10c557ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_seq_si_model = clone_model(non_seq_si_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620459a5",
   "metadata": {},
   "source": [
    "## Compile <ins>non-sequential</ins> model (single-input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de89b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_seq_si_model.compile(loss=\"mse\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28822cdf",
   "metadata": {},
   "source": [
    "## Train <ins>non-sequential</ins> model (single-output) (checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0f7d2295",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    MODEL_PATH + \"district-housing-pricing-nsqsim-v0.1.0.h5\",\n",
    "    save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8a7249e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.1635 - val_loss: 8.9350\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1865 - val_loss: 12.2178\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7754 - val_loss: 8.4328\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4355 - val_loss: 11.9568\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4022 - val_loss: 52.4965\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1039 - val_loss: 7.0756\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1625 - val_loss: 69.5235\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4222 - val_loss: 197.4579\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5300 - val_loss: 73.3077\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.7145 - val_loss: 11.2185\n",
      "CPU times: user 10.2 s, sys: 961 ms, total: 11.2 s\n",
      "Wall time: 5.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "non_seq_si_model_history = non_seq_si_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_validation, y_validation),\n",
    "    callbacks=[checkpoint_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "26fc4a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_seq_si_model_history = load_model(MODEL_PATH + \"district-housing-pricing-nsqsim-v0.1.0.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a7e5d0",
   "metadata": {},
   "source": [
    "## Clone <ins>non-sequential</ins> model (single-input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c3f078d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "24bee819",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_seq_si_model = clone_model(non_seq_si_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f567eedf",
   "metadata": {},
   "source": [
    "## Compile <ins>non-sequential</ins> model (single-input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "880add72",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_seq_si_model.compile(loss=\"mse\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9942908b",
   "metadata": {},
   "source": [
    "## Train <ins>non-sequential</ins> model (single-output) (early-stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "65e09813",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6439a19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.4011 - val_loss: 0.4644\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4753 - val_loss: 0.4305\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4448 - val_loss: 1.2845\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4095 - val_loss: 11.6709\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3975 - val_loss: 16.8489\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6586 - val_loss: 1.5239\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4123 - val_loss: 0.3684\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3771 - val_loss: 18.1488\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3847 - val_loss: 17.8928\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 4.3733 - val_loss: 5.7128\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3720 - val_loss: 43.8080\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.0189 - val_loss: 139.0774\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.6787 - val_loss: 24.8735\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6617 - val_loss: 530.2089\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.0449 - val_loss: 917.0203\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8408 - val_loss: 27.8078\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 7.1907 - val_loss: 0.5353\n",
      "CPU times: user 17.8 s, sys: 1.47 s, total: 19.3 s\n",
      "Wall time: 9.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "non_seq_si_model_history = non_seq_si_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_validation, y_validation),\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742294ad",
   "metadata": {},
   "source": [
    "## Clone <ins>non-sequential</ins> model (single-input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "952bed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "42ec6848",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_seq_si_model = clone_model(non_seq_si_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8695a5d0",
   "metadata": {},
   "source": [
    "## Compile <ins>non-sequential</ins> model (single-input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "26700c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_seq_si_model.compile(loss=\"mse\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65a140f",
   "metadata": {},
   "source": [
    "## Train <ins>non-sequential</ins> model (single-output) (tensorboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9dc8eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = TensorBoard(LOGS_PATH + time.strftime(f\"district-housing-pricing-nsqsim-%Y-%m-%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c3cae85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.2261 - val_loss: 1.0157\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4991 - val_loss: 1.8781\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4868 - val_loss: 11.6870\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4572 - val_loss: 47.8417\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4492 - val_loss: 83.0831\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0185 - val_loss: 1.2780\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.0299 - val_loss: 0.4149\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4653 - val_loss: 1536.6908\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.4894 - val_loss: 0.7194\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4473 - val_loss: 0.8649\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3769 - val_loss: 469.5258\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 86.0860 - val_loss: 55.9820\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "CPU times: user 31.2 s, sys: 2.72 s, total: 33.9 s\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "non_seq_si_model_history = non_seq_si_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=30,\n",
    "    validation_data=(X_validation, y_validation),\n",
    "    callbacks=[tensorboard_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b21e8e7",
   "metadata": {},
   "source": [
    "## Fine-tune <ins>sequential</ins> model (randomized-search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6fdeafb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "376c988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Input(shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(loss=\"mse\", optimizer=SGD(learning_rate))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a9430837",
   "metadata": {},
   "outputs": [],
   "source": [
    "kr_model = KerasRegressor(create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4e2ac5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100).tolist(),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2).rvs(1000).tolist(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d995a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomized_search = RandomizedSearchCV(kr_model, parameters, n_iter=10, cv=3, n_jobs=JOB_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b045fd98",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4025 - val_loss: 0.4468\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4683 - val_loss: 0.4167\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4461 - val_loss: 0.4035\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4511 - val_loss: 0.3993\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4348 - val_loss: 0.3997\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4324 - val_loss: 0.4071\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4389 - val_loss: 0.4146\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4392 - val_loss: 0.3980\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4207 - val_loss: 0.4117\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4324 - val_loss: 0.3942\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4229 - val_loss: 0.3960\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4055 - val_loss: 0.4050\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4371 - val_loss: 0.3893\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4211 - val_loss: 0.3888\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4545 - val_loss: 0.3834\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4203 - val_loss: 0.3872\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4342 - val_loss: 0.3876\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4331 - val_loss: 0.3830\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4140 - val_loss: 0.3829\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4141 - val_loss: 0.3753\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4037 - val_loss: 0.3851\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3988 - val_loss: 0.3772\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4123 - val_loss: 0.3890\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4162 - val_loss: 0.4391\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4123 - val_loss: 0.3922\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3969 - val_loss: 0.3730\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4169 - val_loss: 0.4153\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4323 - val_loss: 0.3832\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4238 - val_loss: 0.3751\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4098 - val_loss: 0.3794\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4081 - val_loss: 0.3687\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4034 - val_loss: 0.3670\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3950 - val_loss: 0.3686\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.3697\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3949 - val_loss: 0.3660\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3901 - val_loss: 0.3682\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3924 - val_loss: 0.3629\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3860 - val_loss: 0.3669\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4246 - val_loss: 0.3720\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3694 - val_loss: 0.3644\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3693\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4040 - val_loss: 0.3721\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3939 - val_loss: 0.3686\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3901 - val_loss: 0.3615\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.3625\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3734 - val_loss: 0.3664\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3797 - val_loss: 0.3598\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.3823\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4001 - val_loss: 0.3619\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3844 - val_loss: 0.3576\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3712 - val_loss: 0.3758\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3986 - val_loss: 0.3607\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3597\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3796 - val_loss: 0.3712\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.3636\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4075 - val_loss: 0.3582\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3796 - val_loss: 0.3595\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.3618\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.3623\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3778 - val_loss: 0.3641\n",
      "121/121 [==============================] - 0s 921us/step - loss: 0.3898\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2336 - val_loss: 1.4221\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4603 - val_loss: 1.0766\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4226 - val_loss: 1.1597\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4290 - val_loss: 1.2806\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4295 - val_loss: 1.4475\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4184 - val_loss: 1.7489\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4020 - val_loss: 1.8776\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4090 - val_loss: 1.9952\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3961 - val_loss: 2.1576\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4038 - val_loss: 1.9811\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3998 - val_loss: 1.9593\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 1.8577\n",
      "121/121 [==============================] - 0s 703us/step - loss: 0.4320\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.9453 - val_loss: 0.6002\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.4797\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4841 - val_loss: 0.4209\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4277 - val_loss: 0.4033\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4328 - val_loss: 0.3980\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4185 - val_loss: 0.4061\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4287 - val_loss: 0.3918\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4658 - val_loss: 0.4983\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4992 - val_loss: 0.4346\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4678 - val_loss: 0.4072\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4629 - val_loss: 0.3942\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4260 - val_loss: 0.3954\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4106 - val_loss: 0.3938\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4140 - val_loss: 0.3943\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4453 - val_loss: 0.3957\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4335 - val_loss: 0.3898\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4182 - val_loss: 0.3970\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4294 - val_loss: 0.4028\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4367 - val_loss: 0.3889\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4290 - val_loss: 0.3916\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4215 - val_loss: 0.3984\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4380 - val_loss: 0.4068\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4154 - val_loss: 0.3978\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4057 - val_loss: 0.3937\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4086 - val_loss: 0.3865\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4125 - val_loss: 0.3896\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4206 - val_loss: 0.4175\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4150 - val_loss: 0.4373\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4607 - val_loss: 0.4850\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4149 - val_loss: 0.4552\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3998 - val_loss: 0.3870\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4081 - val_loss: 0.5651\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.3751\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.3908\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3947 - val_loss: 0.3879\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 0.3909\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4033 - val_loss: 0.3727\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3891 - val_loss: 0.3903\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4083 - val_loss: 0.3679\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.3861\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 0.3871\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.3897\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3989 - val_loss: 0.3657\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4025 - val_loss: 0.3665\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3901 - val_loss: 0.3729\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3819 - val_loss: 0.4015\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3963 - val_loss: 0.3645\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3856 - val_loss: 0.3646\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4005 - val_loss: 0.3706\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3848 - val_loss: 0.4798\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3945 - val_loss: 0.3650\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.3692\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3920 - val_loss: 0.3736\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3839\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3891 - val_loss: 0.3664\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.3666\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.3686\n",
      "121/121 [==============================] - 0s 718us/step - loss: 0.3772\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.6878 - val_loss: 25.9140\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6543 - val_loss: 3.8172\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5207 - val_loss: 0.4772\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4510 - val_loss: 0.4160\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4014 - val_loss: 0.3943\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.4132\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3797 - val_loss: 0.3957\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.4165\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3596 - val_loss: 0.4016\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3626 - val_loss: 0.3929\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3447 - val_loss: 0.3730\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3312 - val_loss: 0.3723\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3587 - val_loss: 0.3813\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.3960\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.3769\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 0.3872\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3483 - val_loss: 0.3825\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3534 - val_loss: 0.3774\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3283 - val_loss: 0.3941\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3392 - val_loss: 0.3573\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.3913\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 0.3666\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3317 - val_loss: 0.3438\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 0.3253\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3301 - val_loss: 0.3666\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3161 - val_loss: 0.3205\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3361 - val_loss: 0.3460\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3242 - val_loss: 0.3574\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3200 - val_loss: 0.3544\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3197 - val_loss: 0.3134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3185 - val_loss: 0.3259\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3084 - val_loss: 0.3083\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3120 - val_loss: 0.3546\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3079 - val_loss: 0.3409\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3060 - val_loss: 0.3083\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3078 - val_loss: 0.3741\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3009 - val_loss: 0.3102\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3130 - val_loss: 0.3798\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3002 - val_loss: 0.3100\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2887 - val_loss: 0.3504\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2984 - val_loss: 0.3059\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3010 - val_loss: 0.3049\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3007 - val_loss: 0.3026\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2955 - val_loss: 0.3763\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3021 - val_loss: 0.3052\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2870 - val_loss: 0.3620\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2905 - val_loss: 0.3250\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2838 - val_loss: 0.3390\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3039 - val_loss: 0.2932\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2896 - val_loss: 0.4189\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2768 - val_loss: 0.3128\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3011 - val_loss: 0.4084\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2861 - val_loss: 0.3002\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2826 - val_loss: 0.3187\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2811 - val_loss: 0.3573\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3034 - val_loss: 0.2957\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2899 - val_loss: 0.4457\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2861 - val_loss: 0.3033\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2916 - val_loss: 0.2924\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2811 - val_loss: 0.3149\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2738 - val_loss: 0.3713\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2780 - val_loss: 0.3057\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2837 - val_loss: 0.4107\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2731 - val_loss: 0.2996\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2660 - val_loss: 0.4692\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2933 - val_loss: 0.5226\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2878 - val_loss: 0.7032\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2788 - val_loss: 0.2874\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2724 - val_loss: 0.3698\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2931 - val_loss: 0.3088\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2819 - val_loss: 0.3365\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2920 - val_loss: 0.3083\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2817 - val_loss: 0.2907\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2831 - val_loss: 0.3812\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2740 - val_loss: 0.2996\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2781 - val_loss: 0.3548\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2678 - val_loss: 0.3000\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2658 - val_loss: 0.4171\n",
      "121/121 [==============================] - 0s 780us/step - loss: 0.3135\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8175 - val_loss: 1.9495\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5426 - val_loss: 0.4390\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4441 - val_loss: 0.4122\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4181 - val_loss: 0.3786\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4029 - val_loss: 0.3692\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.4867\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3665 - val_loss: 0.6287\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3662 - val_loss: 0.6755\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3564 - val_loss: 0.7483\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.5081\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3561 - val_loss: 0.6037\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 0.6690\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3351 - val_loss: 0.7708\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 0.5874\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3560 - val_loss: 0.5832\n",
      "121/121 [==============================] - 0s 770us/step - loss: 0.3512\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.6610 - val_loss: 8.4044\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5906 - val_loss: 7.9506\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4931 - val_loss: 2.8764\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4772 - val_loss: 0.4487\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3967 - val_loss: 0.3996\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3711 - val_loss: 0.4174\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3704 - val_loss: 0.3922\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3851 - val_loss: 0.3854\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.3993\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.3452\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3703 - val_loss: 0.4455\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3494 - val_loss: 0.3358\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3249 - val_loss: 0.3465\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 0.4567\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3597 - val_loss: 0.3327\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3402 - val_loss: 0.3829\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3273 - val_loss: 0.3296\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3365 - val_loss: 0.3375\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3507 - val_loss: 0.3912\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3385 - val_loss: 0.3270\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3320 - val_loss: 0.3787\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 0.3261\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 0.3560\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3189 - val_loss: 0.3704\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3174 - val_loss: 0.3136\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3153 - val_loss: 0.3232\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3308 - val_loss: 0.3631\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3242 - val_loss: 0.3590\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3233 - val_loss: 0.4003\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3199 - val_loss: 0.3187\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3066 - val_loss: 0.3302\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3265 - val_loss: 0.3420\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3120 - val_loss: 0.3781\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3018 - val_loss: 0.3048\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3021 - val_loss: 0.3334\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2959 - val_loss: 0.3074\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3072 - val_loss: 0.3388\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3046 - val_loss: 0.4372\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3148 - val_loss: 0.2992\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3055 - val_loss: 0.4169\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2864 - val_loss: 0.3036\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2911 - val_loss: 0.4764\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3054 - val_loss: 0.3646\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3113 - val_loss: 0.4279\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2950 - val_loss: 0.3034\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2921 - val_loss: 0.3783\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2948 - val_loss: 0.3343\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2878 - val_loss: 0.2977\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2954 - val_loss: 0.3768\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2953 - val_loss: 0.2923\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3003 - val_loss: 0.6462\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2924 - val_loss: 0.3595\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2941 - val_loss: 0.3894\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2870 - val_loss: 0.4306\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2870 - val_loss: 0.9933\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2916 - val_loss: 0.9391\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2939 - val_loss: 0.9884\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3051 - val_loss: 0.4764\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2950 - val_loss: 0.4458\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2918 - val_loss: 0.2906\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2955 - val_loss: 0.3590\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2840 - val_loss: 0.3024\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2814 - val_loss: 0.3946\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2984 - val_loss: 0.4536\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2831 - val_loss: 0.3802\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2749 - val_loss: 0.2821\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2856 - val_loss: 0.2905\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2896 - val_loss: 0.3348\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2730 - val_loss: 0.3317\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2765 - val_loss: 0.3794\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2942 - val_loss: 0.3255\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2678 - val_loss: 0.3095\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2834 - val_loss: 0.3058\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2785 - val_loss: 0.5052\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2757 - val_loss: 0.4709\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2777 - val_loss: 0.7405\n",
      "121/121 [==============================] - 0s 707us/step - loss: 0.3037\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.6953 - val_loss: 5.7404\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2420 - val_loss: 4.1640\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3835 - val_loss: 2.5806\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0117 - val_loss: 1.4971\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8240 - val_loss: 0.9521\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7280 - val_loss: 0.7519\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7087 - val_loss: 0.6685\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6796 - val_loss: 0.6382\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6539 - val_loss: 0.6229\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6525 - val_loss: 0.6117\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6305 - val_loss: 0.6025\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5929 - val_loss: 0.5913\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6350 - val_loss: 0.5839\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6181 - val_loss: 0.5750\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6198 - val_loss: 0.5651\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5881 - val_loss: 0.5580\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6186 - val_loss: 0.5499\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5900 - val_loss: 0.5438\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5717 - val_loss: 0.5369\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5804 - val_loss: 0.5307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5574 - val_loss: 0.5234\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5454 - val_loss: 0.5180\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5627 - val_loss: 0.5124\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5432 - val_loss: 0.5076\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5503 - val_loss: 0.5019\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5250 - val_loss: 0.4970\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5441 - val_loss: 0.4927\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5418 - val_loss: 0.4883\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5479 - val_loss: 0.4842\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5241 - val_loss: 0.4803\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5002 - val_loss: 0.4765\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5073 - val_loss: 0.4732\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4993 - val_loss: 0.4699\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5046 - val_loss: 0.4668\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4931 - val_loss: 0.4642\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4849 - val_loss: 0.4609\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5000 - val_loss: 0.4588\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4708 - val_loss: 0.4556\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4917 - val_loss: 0.4532\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4711 - val_loss: 0.4516\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4807 - val_loss: 0.4490\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4885 - val_loss: 0.4470\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4805 - val_loss: 0.4447\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4692 - val_loss: 0.4430\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4741 - val_loss: 0.4401\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4643 - val_loss: 0.4384\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4720 - val_loss: 0.4373\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4499 - val_loss: 0.4353\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4694 - val_loss: 0.4338\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4578 - val_loss: 0.4322\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4488 - val_loss: 0.4304\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4741 - val_loss: 0.4300\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4595 - val_loss: 0.4292\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4595 - val_loss: 0.4264\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4425 - val_loss: 0.4264\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4846 - val_loss: 0.4258\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4498 - val_loss: 0.4234\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4610 - val_loss: 0.4236\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4589 - val_loss: 0.4216\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4426 - val_loss: 0.4209\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4298 - val_loss: 0.4203\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4400 - val_loss: 0.4200\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4531 - val_loss: 0.4179\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 0.4184\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4200 - val_loss: 0.4178\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4736 - val_loss: 0.4156\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4473 - val_loss: 0.4151\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4401 - val_loss: 0.4155\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4493 - val_loss: 0.4141\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4587 - val_loss: 0.4131\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4353 - val_loss: 0.4132\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4555 - val_loss: 0.4122\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4506 - val_loss: 0.4096\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4383 - val_loss: 0.4103\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4371 - val_loss: 0.4100\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4304 - val_loss: 0.4086\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4249 - val_loss: 0.4070\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4241 - val_loss: 0.4072\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4243 - val_loss: 0.4070\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4290 - val_loss: 0.4062\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4049 - val_loss: 0.4068\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4128 - val_loss: 0.4080\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.4062\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4390 - val_loss: 0.4052\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4275 - val_loss: 0.4034\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4055 - val_loss: 0.4053\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4219 - val_loss: 0.4023\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4215 - val_loss: 0.4002\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4127 - val_loss: 0.3996\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4068 - val_loss: 0.4007\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4332 - val_loss: 0.3984\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4314 - val_loss: 0.3972\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4407 - val_loss: 0.3980\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4246 - val_loss: 0.3973\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3988 - val_loss: 0.3965\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.3962\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4098 - val_loss: 0.3943\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4124 - val_loss: 0.3932\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4143 - val_loss: 0.3970\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4199 - val_loss: 0.3946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 721us/step - loss: 0.4199\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.9155 - val_loss: 6.8010\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.4074 - val_loss: 8.0736\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4961 - val_loss: 8.0777\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 1.136 - 0s 1ms/step - loss: 1.1337 - val_loss: 7.3174\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9372 - val_loss: 6.3162\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8291 - val_loss: 5.3347\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7950 - val_loss: 4.4844\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7314 - val_loss: 3.7406\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7261 - val_loss: 3.1348\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7045 - val_loss: 2.6379\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6889 - val_loss: 2.2279\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6603 - val_loss: 1.8692\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6488 - val_loss: 1.5826\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6450 - val_loss: 1.3537\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6794 - val_loss: 1.1586\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6370 - val_loss: 1.0041\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6422 - val_loss: 0.8783\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6282 - val_loss: 0.7762\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.6955\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6080 - val_loss: 0.6378\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5923 - val_loss: 0.5935\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5961 - val_loss: 0.5663\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5880 - val_loss: 0.5505\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5625 - val_loss: 0.5460\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5505 - val_loss: 0.5514\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5479 - val_loss: 0.5650\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5687 - val_loss: 0.5858\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5610 - val_loss: 0.6132\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5540 - val_loss: 0.6383\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5413 - val_loss: 0.6717\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5344 - val_loss: 0.7104\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5325 - val_loss: 0.7487\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5345 - val_loss: 0.7905\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5136 - val_loss: 0.8267\n",
      "121/121 [==============================] - 0s 627us/step - loss: 0.5361\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.5229 - val_loss: 3.7173\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5034 - val_loss: 2.9295\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9394 - val_loss: 2.0535\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8139 - val_loss: 1.4800\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7320 - val_loss: 1.0955\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6980 - val_loss: 0.8763\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6987 - val_loss: 0.7617\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6866 - val_loss: 0.6872\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6703 - val_loss: 0.6531\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6328 - val_loss: 0.6303\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6462 - val_loss: 0.6140\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6254 - val_loss: 0.6012\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5963 - val_loss: 0.5915\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6048 - val_loss: 0.5826\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6205 - val_loss: 0.5743\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6057 - val_loss: 0.5663\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5807 - val_loss: 0.5587\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6047 - val_loss: 0.5516\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5783 - val_loss: 0.5448\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5674 - val_loss: 0.5381\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5525 - val_loss: 0.5318\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5812 - val_loss: 0.5259\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5416 - val_loss: 0.5202\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5411 - val_loss: 0.5149\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5502 - val_loss: 0.5096\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5301 - val_loss: 0.5046\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5409 - val_loss: 0.4999\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5372 - val_loss: 0.4953\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5209 - val_loss: 0.4916\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5184 - val_loss: 0.4873\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4981 - val_loss: 0.4833\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5306 - val_loss: 0.4800\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5137 - val_loss: 0.4763\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4813 - val_loss: 0.4737\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4859 - val_loss: 0.4705\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4892 - val_loss: 0.4675\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4913 - val_loss: 0.4643\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4850 - val_loss: 0.4618\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4934 - val_loss: 0.4595\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4748 - val_loss: 0.4572\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4607 - val_loss: 0.4569\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4641 - val_loss: 0.4543\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4725 - val_loss: 0.4510\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4782 - val_loss: 0.4494\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4644 - val_loss: 0.4480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4588 - val_loss: 0.4453\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4736 - val_loss: 0.4437\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4581 - val_loss: 0.4425\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4704 - val_loss: 0.4423\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4461 - val_loss: 0.4410\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4690 - val_loss: 0.4398\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4440 - val_loss: 0.4390\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4526 - val_loss: 0.4373\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4523 - val_loss: 0.4350\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4471 - val_loss: 0.4344\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4470 - val_loss: 0.4341\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4400 - val_loss: 0.4339\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4533 - val_loss: 0.4329\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4482 - val_loss: 0.4321\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4617 - val_loss: 0.4307\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4607 - val_loss: 0.4308\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4422 - val_loss: 0.4314\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4334 - val_loss: 0.4290\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4529 - val_loss: 0.4271\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4529 - val_loss: 0.4257\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4287 - val_loss: 0.4273\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4392 - val_loss: 0.4243\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4406 - val_loss: 0.4252\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4192 - val_loss: 0.4231\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4366 - val_loss: 0.4238\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4565 - val_loss: 0.4225\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4133 - val_loss: 0.4232\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4288 - val_loss: 0.4211\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4286 - val_loss: 0.4207\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4178 - val_loss: 0.4215\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4359 - val_loss: 0.4217\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4275 - val_loss: 0.4201\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4276 - val_loss: 0.4203\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4302 - val_loss: 0.4187\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4176 - val_loss: 0.4205\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4138 - val_loss: 0.4199\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4251 - val_loss: 0.4195\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4067 - val_loss: 0.4187\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4281 - val_loss: 0.4192\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4254 - val_loss: 0.4156\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4108 - val_loss: 0.4165\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4201 - val_loss: 0.4191\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4047 - val_loss: 0.4182\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4285 - val_loss: 0.4186\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4150 - val_loss: 0.4156\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4206 - val_loss: 0.4147\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4118 - val_loss: 0.4138\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4019 - val_loss: 0.4149\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4287 - val_loss: 0.4143\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4249 - val_loss: 0.4133\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4034 - val_loss: 0.4138\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4101 - val_loss: 0.4167\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4011 - val_loss: 0.4124\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3974 - val_loss: 0.4133\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3997 - val_loss: 0.4155\n",
      "121/121 [==============================] - 0s 679us/step - loss: 0.4120\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.9427 - val_loss: 4.5934\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6908 - val_loss: 1.2906\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6047 - val_loss: 0.5327\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5592 - val_loss: 0.4954\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5155 - val_loss: 0.4658\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4747 - val_loss: 0.4589\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4694 - val_loss: 0.4254\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4483 - val_loss: 0.4468\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4291 - val_loss: 0.4319\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4250 - val_loss: 0.4201\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4076 - val_loss: 0.3932\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3844 - val_loss: 0.3887\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4189 - val_loss: 0.4121\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3999 - val_loss: 0.4205\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3952 - val_loss: 0.3918\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3865 - val_loss: 0.4051\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3986 - val_loss: 0.4121\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4026 - val_loss: 0.3929\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3784 - val_loss: 0.4124\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3830 - val_loss: 0.3951\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3722 - val_loss: 0.3919\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3625 - val_loss: 0.3950\n",
      "121/121 [==============================] - 0s 736us/step - loss: 0.3831\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.1202 - val_loss: 9.2946\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6806 - val_loss: 4.7403\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5668 - val_loss: 2.6231\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5314 - val_loss: 1.3498\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5028 - val_loss: 0.7573\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4717 - val_loss: 0.5398\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4422 - val_loss: 0.4314\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4335 - val_loss: 0.4065\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4209 - val_loss: 0.3989\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4103 - val_loss: 0.3966\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4066 - val_loss: 0.3873\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3891 - val_loss: 0.3871\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3874 - val_loss: 0.3765\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3753 - val_loss: 0.3797\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3996 - val_loss: 0.3776\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3806 - val_loss: 0.3929\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.4131\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.4415\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3768 - val_loss: 0.4298\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3707 - val_loss: 0.4619\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.4779\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.5054\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3701 - val_loss: 0.5872\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3821\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.5456 - val_loss: 2.2714\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7664 - val_loss: 0.8934\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6365 - val_loss: 0.5574\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5696 - val_loss: 0.5264\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 0.5058\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4846 - val_loss: 0.4669\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4747 - val_loss: 0.4375\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4664 - val_loss: 0.4262\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4480 - val_loss: 0.4531\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4247 - val_loss: 0.3998\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4332 - val_loss: 0.4401\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4104 - val_loss: 0.3951\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3903 - val_loss: 0.3838\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.4445\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4191 - val_loss: 0.3771\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.4192\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3851 - val_loss: 0.3697\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4033 - val_loss: 0.3742\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4037 - val_loss: 0.4082\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3915 - val_loss: 0.3776\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.3853\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3996 - val_loss: 0.3672\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3795 - val_loss: 0.3664\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3727 - val_loss: 0.4237\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3741 - val_loss: 0.3553\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.3609\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3871 - val_loss: 0.4354\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3812 - val_loss: 0.3537\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3677 - val_loss: 0.4514\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3690 - val_loss: 0.3682\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3578 - val_loss: 0.3707\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.4224\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3666 - val_loss: 0.3952\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3500 - val_loss: 0.4139\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3571 - val_loss: 0.3504\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3501 - val_loss: 0.3674\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3644 - val_loss: 0.3437\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3535 - val_loss: 0.4332\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3669 - val_loss: 0.3434\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3596 - val_loss: 0.3980\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.3910\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3452 - val_loss: 0.3960\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.3412\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.4022\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 0.3579\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3438 - val_loss: 0.3955\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.3425\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3440 - val_loss: 0.3413\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 0.4110\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3427 - val_loss: 0.3595\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3495 - val_loss: 0.3987\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3382 - val_loss: 0.3570\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3452 - val_loss: 0.3324\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3417 - val_loss: 0.3390\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3359 - val_loss: 0.3346\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3435 - val_loss: 0.3718\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3359 - val_loss: 0.3760\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.3358\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.3728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3478 - val_loss: 0.3307\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3473 - val_loss: 0.3543\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.3666\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3349 - val_loss: 0.3275\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3485 - val_loss: 0.3501\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3308\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3283 - val_loss: 0.4112\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3399 - val_loss: 0.3380\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.4022\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3262 - val_loss: 0.3372\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 0.3761\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3506 - val_loss: 0.3343\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3182 - val_loss: 0.3612\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3361 - val_loss: 0.3258\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3325 - val_loss: 0.3321\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3247 - val_loss: 0.3441\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3336 - val_loss: 0.4164\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3381 - val_loss: 0.3282\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.3578\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3334 - val_loss: 0.3297\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3257 - val_loss: 0.3492\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3187 - val_loss: 0.3219\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3226 - val_loss: 0.3549\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3179 - val_loss: 0.3249\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 0.3994\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3223 - val_loss: 0.3527\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3191 - val_loss: 0.3713\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 0.3488\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.3186\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3373 - val_loss: 0.3899\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3195 - val_loss: 0.3203\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3307 - val_loss: 0.3811\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3197 - val_loss: 0.4673\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3155 - val_loss: 0.5427\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3344 - val_loss: 0.3490\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3306 - val_loss: 0.4280\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3189 - val_loss: 0.3269\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3218 - val_loss: 0.3440\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3155 - val_loss: 0.3459\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3324\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0855 - val_loss: 154.2510\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8765 - val_loss: 164.7130\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3380 - val_loss: 1537.6282\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.2931 - val_loss: 4160.9238\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8.2332 - val_loss: 22979.6621\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 938.4807 - val_loss: 100139.5703\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 803.0976 - val_loss: 454072.2812\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 12229.8116 - val_loss: 2027159.8750\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 10531.1471 - val_loss: 9209978.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 341841.3223 - val_loss: 45020764.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 647212.4589 - val_loss: 199065968.0000\n",
      "121/121 [==============================] - 0s 657us/step - loss: 527064.6875\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8032 - val_loss: 22.7439\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5144 - val_loss: 23.9352\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5303 - val_loss: 25.2735\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5068 - val_loss: 22.7030\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5090 - val_loss: 22.0467\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5092 - val_loss: 21.4073\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4935 - val_loss: 19.9866\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5216 - val_loss: 22.5629\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5026 - val_loss: 20.1333\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4831 - val_loss: 10.7241\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5128 - val_loss: 19.7485\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4958 - val_loss: 24.3373\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.5081 - val_loss: 25.9584\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4740 - val_loss: 10.5305\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5378 - val_loss: 17.1946\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5078 - val_loss: 21.8375\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4993 - val_loss: 11.7752\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5211 - val_loss: 14.1563\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5103 - val_loss: 20.9823\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4812 - val_loss: 12.3625\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5134 - val_loss: 25.9151\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4890 - val_loss: 16.0463\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5148 - val_loss: 19.4879\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4909 - val_loss: 12.1055\n",
      "121/121 [==============================] - 0s 596us/step - loss: 0.7813\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8455 - val_loss: 333.2213\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0764 - val_loss: 95.4947\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8803 - val_loss: 798.2579\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 42.0905 - val_loss: 705.3528\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0380 - val_loss: 2646.2046\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.1263 - val_loss: 1436.3070\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.2820 - val_loss: 1530.0233\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 71.0781 - val_loss: 1387.4882\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.9861 - val_loss: 1325.8934\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0212 - val_loss: 213.9978\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 21.1007 - val_loss: 123.3619\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7483 - val_loss: 2.0969\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4923 - val_loss: 786.7864\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.4136 - val_loss: 466.1963\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0472 - val_loss: 1070.3612\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 45.0950 - val_loss: 862.8983\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7697 - val_loss: 1125.2837\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.7176 - val_loss: 497.8512\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 34.5730 - val_loss: 308.6057\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.3387 - val_loss: 352.9584\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.4576 - val_loss: 557.5508\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.0712 - val_loss: 392.4270\n",
      "121/121 [==============================] - 0s 610us/step - loss: 0.6217\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7931 - val_loss: 1.9565\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6424 - val_loss: 1.3064\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5552 - val_loss: 0.4661\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5018 - val_loss: 0.4307\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4354 - val_loss: 0.3963\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4054 - val_loss: 0.4098\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3997 - val_loss: 0.3745\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.4329\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3659 - val_loss: 0.4302\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3726 - val_loss: 0.3776\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3494 - val_loss: 0.3846\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 0.3811\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3682 - val_loss: 0.3718\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3521 - val_loss: 0.3870\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.3847\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3433 - val_loss: 0.3954\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3537 - val_loss: 0.3998\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3597 - val_loss: 0.3594\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3383 - val_loss: 0.3603\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3423 - val_loss: 0.3665\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3375 - val_loss: 0.4091\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3287 - val_loss: 0.3568\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 0.4038\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3308 - val_loss: 0.3341\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3388 - val_loss: 0.4155\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3216 - val_loss: 0.3303\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.3894\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 0.3625\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3314 - val_loss: 0.3826\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 0.3259\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3275 - val_loss: 0.3380\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3192 - val_loss: 0.3276\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3202 - val_loss: 0.3420\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3174 - val_loss: 0.3373\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3171 - val_loss: 0.3309\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3158 - val_loss: 0.3551\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3111 - val_loss: 0.3146\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 0.3820\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3114 - val_loss: 0.3235\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3017 - val_loss: 0.3607\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3142 - val_loss: 0.3322\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3185 - val_loss: 0.3287\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3148 - val_loss: 0.3318\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.3612\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3179 - val_loss: 0.3193\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2968 - val_loss: 0.3645\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3052 - val_loss: 0.3290\n",
      "121/121 [==============================] - 0s 733us/step - loss: 0.3407\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8475 - val_loss: 0.5674\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5613 - val_loss: 0.6376\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4642 - val_loss: 0.5815\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4374 - val_loss: 0.4293\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4210 - val_loss: 0.4030\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4009 - val_loss: 0.5720\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.8088\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3851 - val_loss: 1.0934\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 1.3060\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 1.2775\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 1.2956\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3520 - val_loss: 1.4126\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3492 - val_loss: 1.5363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 1.4024\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3678 - val_loss: 1.2737\n",
      "121/121 [==============================] - 0s 746us/step - loss: 0.3767\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.3363 - val_loss: 0.6084\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5756 - val_loss: 0.4696\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4766 - val_loss: 0.4245\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4211 - val_loss: 0.5330\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4074 - val_loss: 0.6940\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3810 - val_loss: 0.5994\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.4619\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4026 - val_loss: 0.4285\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.3613\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3695 - val_loss: 0.4232\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3879 - val_loss: 0.5643\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3650 - val_loss: 0.4813\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3414 - val_loss: 0.3507\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3506 - val_loss: 0.4141\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3747 - val_loss: 0.5735\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3623 - val_loss: 0.5546\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3451 - val_loss: 0.4152\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3577 - val_loss: 0.3765\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3705 - val_loss: 0.3338\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.3390\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3475 - val_loss: 0.3406\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3595 - val_loss: 0.3968\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3432 - val_loss: 0.3654\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 0.3864\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3339 - val_loss: 0.3308\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3310 - val_loss: 0.8747\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3990 - val_loss: 0.5529\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3444 - val_loss: 0.3490\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3556 - val_loss: 0.3570\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3392 - val_loss: 0.3557\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3231 - val_loss: 0.3260\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.3452\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3283 - val_loss: 0.3300\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3155 - val_loss: 0.3340\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3207 - val_loss: 0.3164\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3121 - val_loss: 0.3237\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3206 - val_loss: 0.4888\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3231 - val_loss: 0.5531\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3310 - val_loss: 0.3146\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3222 - val_loss: 0.3519\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2993 - val_loss: 0.3313\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3059 - val_loss: 0.3329\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3226 - val_loss: 0.3073\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3230 - val_loss: 0.3292\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3138 - val_loss: 0.3181\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3065 - val_loss: 0.3284\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3106 - val_loss: 0.3206\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3022 - val_loss: 0.3078\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3143 - val_loss: 0.3567\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3092 - val_loss: 0.3088\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3118 - val_loss: 0.3601\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2986 - val_loss: 0.3038\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3100 - val_loss: 0.3136\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3037 - val_loss: 0.3068\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2988 - val_loss: 0.3265\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3017 - val_loss: 0.2987\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3012 - val_loss: 0.3373\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3096 - val_loss: 0.3040\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3102 - val_loss: 0.3651\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3054 - val_loss: 0.2983\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3032 - val_loss: 0.3268\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2970 - val_loss: 0.3045\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2956 - val_loss: 0.3044\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3122 - val_loss: 0.3277\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2974 - val_loss: 0.3054\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2872 - val_loss: 0.3420\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.4127\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3088 - val_loss: 0.4788\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2916 - val_loss: 0.3471\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2916 - val_loss: 0.3567\n",
      "121/121 [==============================] - 0s 714us/step - loss: 0.3105\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.2085 - val_loss: 13.0320\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7345 - val_loss: 7.5293\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6553 - val_loss: 2.0053\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5715 - val_loss: 0.7201\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5217 - val_loss: 0.5000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4880 - val_loss: 0.4586\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4801 - val_loss: 0.4438\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4595 - val_loss: 0.4334\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4437 - val_loss: 0.4281\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4384 - val_loss: 0.4095\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4235 - val_loss: 0.4026\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4026 - val_loss: 0.4010\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4314 - val_loss: 0.3942\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4174 - val_loss: 0.4109\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4158 - val_loss: 0.4058\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.3865\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4217 - val_loss: 0.4241\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4197 - val_loss: 0.3830\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3961 - val_loss: 0.3970\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4038 - val_loss: 0.3877\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.4097\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.3759\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4018 - val_loss: 0.3965\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.3684\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.4074\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.3655\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3979 - val_loss: 0.4034\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.3825\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.4034\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3624\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.3639\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.3593\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.3789\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 0.3785\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3707 - val_loss: 0.3578\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3687 - val_loss: 0.3973\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3711 - val_loss: 0.3657\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3741 - val_loss: 0.4579\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3712 - val_loss: 0.3571\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3538 - val_loss: 0.4212\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.3543\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3679 - val_loss: 0.3586\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3672 - val_loss: 0.3536\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3681 - val_loss: 0.4019\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3699 - val_loss: 0.3539\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3537 - val_loss: 0.3646\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3653 - val_loss: 0.3833\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3472 - val_loss: 0.3610\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3741 - val_loss: 0.3481\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3573 - val_loss: 0.4163\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3461 - val_loss: 0.3633\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3709 - val_loss: 0.3575\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3546 - val_loss: 0.3596\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3618 - val_loss: 0.3466\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3478 - val_loss: 0.3950\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.3450\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.4209\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3651 - val_loss: 0.3630\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3657 - val_loss: 0.3435\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3539 - val_loss: 0.3659\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3447 - val_loss: 0.3664\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3496 - val_loss: 0.3979\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3643 - val_loss: 0.3526\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3444 - val_loss: 0.4178\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3362 - val_loss: 0.3725\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.3462\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3555 - val_loss: 0.3942\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3539 - val_loss: 0.3436\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3592 - val_loss: 0.4207\n",
      "121/121 [==============================] - 0s 659us/step - loss: 0.3725\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.5548 - val_loss: 11.0818\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7715 - val_loss: 5.4288\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6390 - val_loss: 2.7197\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5877 - val_loss: 1.2564\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5550 - val_loss: 0.6706\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5148 - val_loss: 0.4892\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4833 - val_loss: 0.4652\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4689 - val_loss: 0.5137\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4561 - val_loss: 0.5395\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4466 - val_loss: 0.5722\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4412 - val_loss: 0.5752\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4199 - val_loss: 0.5945\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4219 - val_loss: 0.5786\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4082 - val_loss: 0.5153\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4357 - val_loss: 0.4859\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4167 - val_loss: 0.4535\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4191 - val_loss: 0.4251\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4244 - val_loss: 0.4011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.3946\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.3831\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4044 - val_loss: 0.3778\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.3777\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4059 - val_loss: 0.3883\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.3942\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3737 - val_loss: 0.4116\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3849 - val_loss: 0.4279\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4003 - val_loss: 0.4464\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3918 - val_loss: 0.4701\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.5208\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.5327\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.5409\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.5694\n",
      "121/121 [==============================] - 0s 710us/step - loss: 0.3986\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.5332 - val_loss: 14.8939\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7262 - val_loss: 9.8363\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6405 - val_loss: 4.0816\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6304 - val_loss: 1.5048\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5240 - val_loss: 0.7455\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4860 - val_loss: 0.5419\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4802 - val_loss: 0.5443\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4799 - val_loss: 0.4612\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4588 - val_loss: 0.4528\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4399 - val_loss: 0.4630\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4461 - val_loss: 0.4472\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4272 - val_loss: 0.4253\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4029 - val_loss: 0.4103\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4132 - val_loss: 0.4420\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4367 - val_loss: 0.4703\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4262 - val_loss: 0.4836\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4061 - val_loss: 0.5447\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4239 - val_loss: 0.4078\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4244 - val_loss: 0.3858\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4120 - val_loss: 0.3852\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4026 - val_loss: 0.3831\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4246 - val_loss: 0.3863\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4037 - val_loss: 0.4047\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4005 - val_loss: 0.4279\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4011 - val_loss: 0.5882\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3999 - val_loss: 0.3793\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4106 - val_loss: 0.3943\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4066 - val_loss: 0.4485\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3912 - val_loss: 0.5622\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3978 - val_loss: 0.4577\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3862 - val_loss: 0.3961\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4138 - val_loss: 0.3741\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3924 - val_loss: 0.3802\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.3849\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3859 - val_loss: 0.3765\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3782 - val_loss: 0.3688\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3904 - val_loss: 0.5733\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.6939\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3971 - val_loss: 0.7366\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.6638\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3841 - val_loss: 0.4151\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.4798\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.8283\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3930 - val_loss: 0.7352\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3842 - val_loss: 0.6197\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.7137\n",
      "121/121 [==============================] - 0s 669us/step - loss: 0.3792\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5427 - val_loss: 1.7104\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4950 - val_loss: 11.2827\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4853 - val_loss: 0.3817\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4147 - val_loss: 0.3858\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3727 - val_loss: 0.3746\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3620 - val_loss: 0.5833\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3614 - val_loss: 0.3474\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3540 - val_loss: 0.5251\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.3558\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3436 - val_loss: 0.5069\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3306 - val_loss: 0.3298\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3172 - val_loss: 0.3895\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3438 - val_loss: 0.4181\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3285 - val_loss: 0.3858\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3262 - val_loss: 0.3884\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3254 - val_loss: 0.3848\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 0.3997\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3360 - val_loss: 0.3700\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3135 - val_loss: 0.4735\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3220 - val_loss: 0.3209\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3172 - val_loss: 0.4901\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3098 - val_loss: 0.3270\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3130 - val_loss: 0.5365\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3103 - val_loss: 0.3906\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3156 - val_loss: 0.6041\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2974 - val_loss: 0.4065\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3247 - val_loss: 0.5300\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3067 - val_loss: 0.3152\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3026 - val_loss: 0.3709\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3008 - val_loss: 0.3102\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2998 - val_loss: 0.3192\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2870 - val_loss: 0.2925\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.3550\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2873 - val_loss: 0.3766\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2865 - val_loss: 0.2973\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2922 - val_loss: 0.6189\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2769 - val_loss: 0.8950\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3193 - val_loss: 0.4347\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2847 - val_loss: 0.3119\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2698 - val_loss: 0.3392\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2817 - val_loss: 0.3090\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2827 - val_loss: 0.3104\n",
      "121/121 [==============================] - 0s 683us/step - loss: 0.3211\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5340 - val_loss: 0.5252\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5109 - val_loss: 0.6917\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4218 - val_loss: 0.3850\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4001 - val_loss: 0.3808\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3823 - val_loss: 0.4270\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3631 - val_loss: 0.5880\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3511 - val_loss: 0.9095\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3546 - val_loss: 0.8874\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 1.0496\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3443 - val_loss: 0.7416\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3400 - val_loss: 0.7709\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3255 - val_loss: 0.8631\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3210 - val_loss: 0.9736\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3127 - val_loss: 0.9198\n",
      "121/121 [==============================] - 0s 693us/step - loss: 0.3583\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5241 - val_loss: 0.5229\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5020 - val_loss: 1.2970\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4314 - val_loss: 5.7693\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5307 - val_loss: 3.6886\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3747 - val_loss: 0.3970\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3536 - val_loss: 0.4956\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3517 - val_loss: 0.3421\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3724 - val_loss: 0.3894\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 0.4000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3467 - val_loss: 0.3329\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3582 - val_loss: 0.4063\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3347 - val_loss: 0.3331\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3094 - val_loss: 0.3293\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3211 - val_loss: 0.4470\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3422 - val_loss: 0.3286\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3265 - val_loss: 0.3475\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3140 - val_loss: 0.3411\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3223 - val_loss: 0.3236\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3387 - val_loss: 0.3914\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3262 - val_loss: 0.3407\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3179 - val_loss: 0.3944\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3292 - val_loss: 0.3140\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3145 - val_loss: 0.3235\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3051 - val_loss: 0.3530\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3026 - val_loss: 0.3092\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3033 - val_loss: 0.3145\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3187 - val_loss: 0.3904\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3134 - val_loss: 0.3078\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3089 - val_loss: 0.3293\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3046 - val_loss: 0.3788\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2939 - val_loss: 0.3177\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3102 - val_loss: 0.3748\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3006 - val_loss: 0.3426\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2908 - val_loss: 0.3205\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2897 - val_loss: 0.2969\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2831 - val_loss: 0.3314\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2941 - val_loss: 0.2965\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2932 - val_loss: 0.3624\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3023 - val_loss: 0.2980\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2918 - val_loss: 0.3364\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2728 - val_loss: 0.3329\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 0.3547\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2940 - val_loss: 0.2934\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2941 - val_loss: 0.3463\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2745 - val_loss: 0.3179\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2781 - val_loss: 0.3738\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2806 - val_loss: 0.2983\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2762 - val_loss: 0.2867\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2836 - val_loss: 0.3657\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2825 - val_loss: 0.3174\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2878 - val_loss: 0.3332\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2713 - val_loss: 0.3120\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2789 - val_loss: 0.3013\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 0.3038\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2695 - val_loss: 0.2920\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2790 - val_loss: 0.3019\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2753 - val_loss: 0.3102\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2842 - val_loss: 0.2953\n",
      "121/121 [==============================] - 0s 702us/step - loss: 0.2972\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.8180 - val_loss: 1.0707\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5585 - val_loss: 1.5666\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4776 - val_loss: 0.5489\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4389 - val_loss: 0.4104\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3868 - val_loss: 0.3695\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3631 - val_loss: 0.4256\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3590 - val_loss: 0.3511\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3473 - val_loss: 0.4641\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3382 - val_loss: 0.3821\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3415 - val_loss: 0.4521\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3238 - val_loss: 0.3264\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3129 - val_loss: 0.3769\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3357 - val_loss: 0.4516\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3270 - val_loss: 0.3714\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3206 - val_loss: 0.4761\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3179 - val_loss: 0.3288\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3268 - val_loss: 0.6442\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3352 - val_loss: 0.3529\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3131 - val_loss: 0.4970\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3177 - val_loss: 0.3333\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3117 - val_loss: 0.4278\n",
      "121/121 [==============================] - 0s 664us/step - loss: 0.3333\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4468 - val_loss: 1.5823\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4898 - val_loss: 0.6710\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4053 - val_loss: 0.8372\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.7808\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3778 - val_loss: 0.8486\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3588 - val_loss: 1.1112\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3452 - val_loss: 1.3436\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3485 - val_loss: 1.3240\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 1.2086\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.6897\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3400 - val_loss: 0.9156\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3247 - val_loss: 0.9035\n",
      "121/121 [==============================] - 0s 745us/step - loss: 0.3547\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7222 - val_loss: 0.5954\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5105 - val_loss: 0.4604\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4417 - val_loss: 0.3873\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.4677\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.3548\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.4026\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3492 - val_loss: 0.3529\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3713 - val_loss: 0.3578\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.3951\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.3258\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3524 - val_loss: 0.4406\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3344 - val_loss: 0.3297\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3110 - val_loss: 0.3401\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3205 - val_loss: 0.4242\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3422 - val_loss: 0.3412\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3232 - val_loss: 0.3998\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3134 - val_loss: 0.3191\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3233 - val_loss: 0.3549\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3345 - val_loss: 0.3697\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3236 - val_loss: 0.3574\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3164 - val_loss: 0.3479\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3285 - val_loss: 0.3258\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3114 - val_loss: 0.3904\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3021 - val_loss: 0.3584\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3029 - val_loss: 0.3099\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3042 - val_loss: 0.3287\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3152 - val_loss: 0.3947\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3112 - val_loss: 0.4034\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3131 - val_loss: 0.5603\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3055 - val_loss: 0.3044\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2961 - val_loss: 0.3673\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3084 - val_loss: 0.3654\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3022 - val_loss: 0.4206\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2910 - val_loss: 0.3156\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2877 - val_loss: 0.2979\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2833 - val_loss: 0.4892\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2927 - val_loss: 0.4410\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2976 - val_loss: 0.6944\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3025 - val_loss: 0.3318\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2887 - val_loss: 0.7760\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2953 - val_loss: 0.3243\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2826 - val_loss: 0.6711\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2978 - val_loss: 0.5005\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3014 - val_loss: 0.4600\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2842 - val_loss: 0.2999\n",
      "121/121 [==============================] - 0s 741us/step - loss: 0.3128\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.0686 - val_loss: 13.9906\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6538 - val_loss: 1.6407\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5252 - val_loss: 0.5196\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4643 - val_loss: 0.4182\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4141 - val_loss: 0.4014\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3902 - val_loss: 0.4155\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.3975\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.4104\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.4070\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 0.3978\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3558 - val_loss: 0.3824\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.3711\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3704 - val_loss: 0.3890\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.4016\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3521 - val_loss: 0.3771\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3477 - val_loss: 0.3867\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3575 - val_loss: 0.3946\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3657 - val_loss: 0.3826\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.3810\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3483 - val_loss: 0.3706\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3409 - val_loss: 0.3771\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.3742\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3422 - val_loss: 0.3684\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3364 - val_loss: 0.3453\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3425 - val_loss: 0.3717\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3251 - val_loss: 0.3410\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3441 - val_loss: 0.3607\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3373 - val_loss: 0.3686\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3350 - val_loss: 0.3619\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3318 - val_loss: 0.3341\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3320 - val_loss: 0.3333\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3195 - val_loss: 0.3279\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3251 - val_loss: 0.3491\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3221 - val_loss: 0.3502\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3175 - val_loss: 0.3246\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3205 - val_loss: 0.3586\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3156 - val_loss: 0.3149\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3269 - val_loss: 0.3612\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3158 - val_loss: 0.3255\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3058 - val_loss: 0.3558\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3168 - val_loss: 0.3205\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3171 - val_loss: 0.3241\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3159 - val_loss: 0.3224\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3123 - val_loss: 0.3576\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3210 - val_loss: 0.3120\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3029 - val_loss: 0.3351\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3074 - val_loss: 0.3439\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2986 - val_loss: 0.3295\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3229 - val_loss: 0.3126\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3045 - val_loss: 0.3514\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2965 - val_loss: 0.3455\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3224 - val_loss: 0.3438\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3034 - val_loss: 0.3297\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3015 - val_loss: 0.3121\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2995 - val_loss: 0.3613\n",
      "121/121 [==============================] - 0s 718us/step - loss: 0.3422\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8564 - val_loss: 0.6571\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5546 - val_loss: 0.8773\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4656 - val_loss: 0.8489\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4429 - val_loss: 0.7159\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4193 - val_loss: 0.4803\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3947 - val_loss: 0.3800\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.4573\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3803 - val_loss: 0.5505\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.7511\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3680 - val_loss: 0.5710\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3664 - val_loss: 0.7416\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.6936\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3478 - val_loss: 0.8288\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3364 - val_loss: 0.7480\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3676 - val_loss: 0.6765\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 0.7576\n",
      "121/121 [==============================] - 0s 690us/step - loss: 0.3654\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8481 - val_loss: 2.1580\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5919 - val_loss: 7.3978\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5211 - val_loss: 14.5884\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8325 - val_loss: 2.5296\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4243 - val_loss: 0.4192\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3874 - val_loss: 0.4215\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.4174\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3994 - val_loss: 0.3934\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3794 - val_loss: 0.4163\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3722 - val_loss: 0.3803\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.4291\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3609 - val_loss: 0.4282\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 0.3606\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.4002\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3754 - val_loss: 0.3722\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.3975\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3418 - val_loss: 0.3637\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3524 - val_loss: 0.3646\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3656 - val_loss: 0.3807\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.3683\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.3737\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3583 - val_loss: 0.3350\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 0.3492\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3342 - val_loss: 0.3973\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3325 - val_loss: 0.3253\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3300 - val_loss: 0.3354\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3479 - val_loss: 0.3658\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3440 - val_loss: 0.3327\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 0.3644\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3351 - val_loss: 0.3487\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3194 - val_loss: 0.3529\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.3822\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3275 - val_loss: 0.3540\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3156 - val_loss: 0.3854\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3218 - val_loss: 0.3191\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3133 - val_loss: 0.3766\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 0.3156\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3202 - val_loss: 0.3347\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3352 - val_loss: 0.3237\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3274 - val_loss: 0.3349\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3004 - val_loss: 0.3673\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.3616\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 0.3091\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3296 - val_loss: 0.3258\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3088 - val_loss: 0.3525\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3076 - val_loss: 0.3493\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3142 - val_loss: 0.3050\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3071 - val_loss: 0.3217\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3149 - val_loss: 0.3765\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3133 - val_loss: 0.3237\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3186 - val_loss: 0.3581\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3041 - val_loss: 0.3232\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3105 - val_loss: 0.3039\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3089 - val_loss: 0.3386\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3043 - val_loss: 0.3006\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3108 - val_loss: 0.3718\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3051 - val_loss: 0.3223\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3129 - val_loss: 0.3038\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3107 - val_loss: 0.3453\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3089 - val_loss: 0.3054\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3145 - val_loss: 0.3292\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3021 - val_loss: 0.3059\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2996 - val_loss: 0.3003\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3150 - val_loss: 0.3538\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3000 - val_loss: 0.3183\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2961 - val_loss: 0.4509\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3064 - val_loss: 0.3286\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3105 - val_loss: 0.3216\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2940 - val_loss: 0.3048\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2968 - val_loss: 0.3129\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3147 - val_loss: 0.3006\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2860 - val_loss: 0.3126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3030 - val_loss: 0.3005\n",
      "121/121 [==============================] - 0s 711us/step - loss: 0.3112\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.5270 - val_loss: 7.6103\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7730 - val_loss: 10.1614\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5730 - val_loss: 0.8135\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4150 - val_loss: 0.3607\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.3698\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.3955\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.4043\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.3949\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3597 - val_loss: 0.4008\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3620 - val_loss: 0.4183\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3472 - val_loss: 0.3716\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.4122\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3452 - val_loss: 0.3692\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3418 - val_loss: 0.3603\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3388 - val_loss: 0.3653\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3433 - val_loss: 0.3497\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3263 - val_loss: 0.3731\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 0.3493\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 0.3424\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3156 - val_loss: 0.4077\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3245 - val_loss: 0.3336\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3129 - val_loss: 0.3785\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3312 - val_loss: 0.3211\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3187 - val_loss: 0.3551\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3161 - val_loss: 0.3640\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3180 - val_loss: 0.3762\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3193 - val_loss: 0.3076\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3201 - val_loss: 0.3616\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3113 - val_loss: 0.3265\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3205 - val_loss: 0.3954\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3140 - val_loss: 0.3105\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3083 - val_loss: 0.3857\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3104 - val_loss: 0.3007\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3035 - val_loss: 0.3157\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2975 - val_loss: 0.3879\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2967 - val_loss: 0.3630\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3234 - val_loss: 0.3951\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3007 - val_loss: 0.2991\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3185 - val_loss: 0.3319\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2985 - val_loss: 0.3345\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3109 - val_loss: 0.4159\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2944 - val_loss: 0.2942\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3060 - val_loss: 0.4224\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2930 - val_loss: 0.2929\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2977 - val_loss: 0.2959\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2965 - val_loss: 0.2942\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3058 - val_loss: 0.3378\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2861 - val_loss: 0.3387\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2964 - val_loss: 0.3214\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2982 - val_loss: 0.2840\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.2881\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2877 - val_loss: 0.2889\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2915 - val_loss: 0.5123\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2790 - val_loss: 0.7032\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2923 - val_loss: 0.6557\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2832 - val_loss: 0.6091\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2830 - val_loss: 0.6724\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2749 - val_loss: 0.2924\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2837 - val_loss: 0.5194\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2809 - val_loss: 0.3754\n",
      "CPU times: user 16min 24s, sys: 1min 22s, total: 17min 47s\n",
      "Wall time: 8min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fa53ae91b20>,\n",
       "                   n_jobs=1,\n",
       "                   param_distributions={'learning_rate': [0.001683454924600351,\n",
       "                                                          0.02390836445593178,\n",
       "                                                          0.008731907739399206,\n",
       "                                                          0.004725396149933917,\n",
       "                                                          0.0006154014789262348,\n",
       "                                                          0.0006153331256530192,\n",
       "                                                          0.0003920021771415983,\n",
       "                                                          0.01619845322936229,\n",
       "                                                          0.0047791567848...\n",
       "                                                          0.0011470425674025553,\n",
       "                                                          0.005021425736625637,\n",
       "                                                          0.0005703073595961105,\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.001621231156394198,\n",
       "                                                          0.0024505367684280487,\n",
       "                                                          0.011155092541719619,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.0032032448128444043,\n",
       "                                                          0.004591455636549438,\n",
       "                                                          0.0003715541189658278, ...],\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...]})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "randomized_search.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_validation, y_validation),\n",
    "    callbacks=[EarlyStopping(patience=10)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2d379b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3228167990843455"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bd139e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 94, 'n_hidden': 2, 'learning_rate': 0.005432590230265343}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9bcc7633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fa53ac05460>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_search.best_estimator_.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caf581b",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ae5535",
   "metadata": {},
   "source": [
    "1. Visit the TensorFlow Playground at [https://playground.tensorflow.org/](https://playground.tensorflow.org/)\n",
    "\n",
    "* Layers and patterns: try training the default neural network by clicking the run button (top left). Notice how it quickly finds a good solution for the classification task. Notice that the neurons in the first hidden layer have learned simple patterns, while the neurons in the second hidden layer have learned to combine the simple patterns of the first hidden layer into more complex patterns. In general, the more layers, the more complex the patterns can be.\n",
    "\n",
    "* Activation function: try replacing the Tanh activation function with the ReLU activation function, and train the network again. Notice that it finds a solution even faster, but this time the boundaries are linear. This is due to the shape of the ReLU function.\n",
    "\n",
    "* Local minima: modify the network architecture to have just one hidden layer with three neurons. Train it multiple times (to reset the network weights, click the reset button next to the play button). Notice that the training time varies a lot, and sometimes it even gets stuck in a local minimum.\n",
    "\n",
    "* Too small: now remove one neuron to keep just 2. Notice that the neural network is now incapable of finding a good solution, even if you try multiple times. The model has too few parameters and it systematically underfits the training set.\n",
    "\n",
    "* Large enough: next, set the number of neurons to 8 and train the network several times. Notice that it is now consistently fast and never gets stuck. This highlights an important finding in neural network theory: large neural networks almost never get stuck in local minima, and even when they do these local optima are almost as good as the global optimum. However, they can still get stuck on long plateaus for a long time.\n",
    "\n",
    "* Deep net and vanishing gradients: now change the dataset to be the spiral (bottom right dataset under \"DATA\"). Change the network architecture to have 4 hidden layers with 8 neurons each. Notice that training takes much longer, and often gets stuck on plateaus for long periods of time. Also notice that the neurons in the highest layers (i.e. on the right) tend to evolve faster than the neurons in the lowest layers (i.e. on the left). This problem, called the \"vanishing gradients\" problem, can be alleviated using better weight initialization and other techniques, better optimizers (such as AdaGrad or Adam), or using Batch Normalization.\n",
    "\n",
    "* More: go ahead and play with the other parameters to get a feel of what they do. In fact, you should definitely play with this UI for at least one hour, it will grow your intuitions about neural networks significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5135e4ba",
   "metadata": {},
   "source": [
    "2. Draw an ANN using the original artificial neurons that computes A ⊕ B (where ⊕ represents the XOR operation). Hint: A ⊕ B = (A∧ ¬ B) ∨ (¬ A ∧ B)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa52860e",
   "metadata": {},
   "source": [
    "3. Why is it generally preferable to use a Logistic Regression classifier rather than a classical Perceptron (i.e., a single layer of threshold logic units trained using the Perceptron training algorithm)? How can you tweak a Perceptron to make it equivalent to a Logistic Regression classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a55f9bb",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "An perceptron will only converge if the data is linearly separable. You can make a perceptron equivalent to a logistic regression classifier by changing the activation function to logistic and training it with gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeed698",
   "metadata": {},
   "source": [
    "4. Why was the logistic activation function a key ingredient in training the first MLPs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f9cae",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "Because the derivative of a logistic activation function is not zero therefore gradient descent can always converge to the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99912403",
   "metadata": {},
   "source": [
    "5. Name three popular activation functions. Can you draw them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3b510",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "* Step\n",
    "\n",
    "* Logistic\n",
    "\n",
    "* ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d98f77",
   "metadata": {},
   "source": [
    "6. Suppose you have an MLP composed of one input layer with 10 passthrough neurons, followed by one hidden layer with 50 artificial neurons, and finally one output layer with 3 artificial neurons. All artificial neurons use the ReLU activation function.\n",
    "\n",
    "* What is the shape of the input matrix $X$?\n",
    "\n",
    "* What about the shape of the hidden layer's weight vector $W_h$, and the shape of its bias vector $b_h$?\n",
    "\n",
    "* What is the shape of the output layer's weight vector $W_o$, and its bias vector $b_o$?\n",
    "\n",
    "* What is the shape of the network's output matrix $Y$?\n",
    "\n",
    "* Write the equation that computes the network's output matrix $Y$ as a function of $X$, $W_h$, $b_h$, $W_o$ and $b_o$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76a3793",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "* Input matrix: $m \\cdot 10$ ($m$ = training batch)\n",
    "\n",
    "* Hidden layer shape: $W_h = 10 \\cdot 50$, Bias vector shape: $b_h = 50$\n",
    "\n",
    "* Output layer shape: $W_o = 50 \\cdot 3$, Bias vector shape: $B_o = 3$\n",
    "\n",
    "* Output matrix: $Y = m \\cdot 3$ ($m$ = training batch)\n",
    "\n",
    "* Output matrix equation: $Y = ReLU(ReLu(X \\cdot W_h + b_h) \\cdot W_o + b_o)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50417b4a",
   "metadata": {},
   "source": [
    "7. How many neurons do you need in the output layer if you want to classify email into spam or ham? What activation function should you use in the output layer? If instead you want to tackle MNIST, how many neurons do you need in the output layer, using what activation function? Answer the same questions for getting your network to predict housing prices as in Chapter 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd10a2",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "*Classify Email*\n",
    "\n",
    "* Output layer neurons: 1\n",
    "\n",
    "* Output layer function: logistic\n",
    "\n",
    "*Classify MNIST*\n",
    "\n",
    "* Output layer neurons: 10\n",
    "\n",
    "* Output layer function: softmax\n",
    "\n",
    "*Regression Housing*\n",
    "\n",
    "* Output layer neurons: 1\n",
    "\n",
    "* Output layer function: none"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8d9952",
   "metadata": {},
   "source": [
    "8. What is backpropagation and how does it work? What is the difference between backpropagation and reverse-mode autodiff?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de747a1",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "Backpropagation is a technique used to train neural networks. It first computes the gradients of the cost function with regards to all the weights and biases, and then it performs a gradient descent step using these gradients. It repeats this process until the model parameters converge to a values that minimize the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178defda",
   "metadata": {},
   "source": [
    "9. Can you list all the hyperparameters you can tweak in an MLP? If the MLP overfits the training data, how could you tweak these hyperparameters to try to solve the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3088ccf0",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "* The number of hidden layers,\n",
    "\n",
    "* The number of neurons in each hidden layer\n",
    "\n",
    "* The activation function used in each hidden layer and the output layer\n",
    "\n",
    "Reducing the number of hidden layers and the number of neurons per hidden layer might help the model to stop overfitting the training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
